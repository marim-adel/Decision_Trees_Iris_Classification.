ğŸŒ¸ Iris Classification with Decision Tree
ğŸ“Œ Overview

This project applies a Decision Tree Classifier to the classic Iris dataset (150 samples, 4 features, 3 classes).
The goal is to explore the dataset, preprocess it, train a decision tree, and evaluate classification performance.

ğŸ“Š Dataset & EDA

Dataset: Iris Dataset

Features:

Sepal Length

Sepal Width

Petal Length

Petal Width

Target classes:

Setosa

Versicolor

Virginica

Exploratory Data Analysis (EDA)

âœ” Checked missing values â†’ none found.
âœ” Removed duplicate rows â†’ 1 duplicate removed.
âœ” Plotted pairplots and correlations for feature relationships.

âš™ï¸ Preprocessing

Dropped duplicates from df.

Scaled features using StandardScaler.

Train-test split: 80/20 with stratified sampling.

ğŸŒ³ Model Training

Algorithm: Decision Tree Classifier

Parameters:

max_depth=2 (controlled complexity to avoid overfitting)

random_state=42 (reproducibility)

Trained on scaled features X_train, y_train.

ğŸ“ˆ Evaluation
Metrics
Accuracy: 0.67
F1 Score: 0.56

Classification Report:
              precision    recall  f1-score   support

      setosa       1.00      1.00      1.00        15
  versicolor       0.50      1.00      0.67        15
   virginica       0.00      0.00      0.00        15

ğŸ” Summary

Setosa: Perfectly classified âœ…

Versicolor: High recall (1.0) but precision suffers (0.5)

Virginica: Not correctly classified âŒ

Overall Accuracy: ~67% â†’ indicates underfitting due to shallow tree.

ğŸš€ Next Steps

To improve accuracy toward 95%+:

Increase max_depth or tune min_samples_split / min_samples_leaf.

Try Random Forest or Gradient Boosting.

Use cross-validation to better estimate generalization.

Visualize tree structure for interpretability.active predictions.
